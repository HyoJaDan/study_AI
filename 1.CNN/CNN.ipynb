{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP6/6SNF6sil2ojcn0gdzDe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HyoJaDan/CNN/blob/main/Untitled2_ipynb%EC%9D%98_%EC%82%AC%EB%B3%B8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5PkfHZrLYDfe",
        "outputId": "91effc93-93b1-4030-ea70-fb75180ebe9c"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 138407619.68it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./MNIST/raw/train-images-idx3-ubyte.gz to ./MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 56133315.03it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./MNIST/raw/train-labels-idx1-ubyte.gz to ./MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 31867823.85it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./MNIST/raw/t10k-images-idx3-ubyte.gz to ./MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 12500346.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./MNIST/raw/t10k-labels-idx1-ubyte.gz to ./MNIST/raw\n",
            "\n",
            "tensor(2.3033, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3061, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1146, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0718, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0563, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0479, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0611, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0854, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0757, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0568, grad_fn=<NllLossBackward0>)\n",
            "Accuracy of Test Data : 99.03845977783203\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.init as init\n",
        "import matplotlib.pyplot as plt\n",
        "import torchvision.datasets as dset\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "#MNIST라는 숫자 데이터셋을 다운받기위해 torchvision이라는 라이브러리를 미리 다운로드 해줍니다.\n",
        "#가지고 있는 데이터의 순서를 섞거나, 원하는 비율로 나누거나...하는\n",
        "#데이터 전처리를 위해 DataLoader를 선언\n",
        "\n",
        "batch_size = 256\n",
        "learning_rate = 0.0002\n",
        "num_epoch = 10\n",
        "#CNN에서 batch_size 는 한번에 학습하는 이미지의 수 입니다. 즉, MNIST는 6만장의 데이터가 있는데요\n",
        "#이걸 한장한장씩 학습하는게 아니라, 256개씩 묶어서 진행하겠다는 뜻입니다.(256이 아니어도 됩니다.)\n",
        "#6만장의 사진을 학습하므로, learning rate는 조금 낮게 잡는게 발산할 수 있는 가능성을 낮추어줍니다.\n",
        "#데이터 사이즈가 큰 관계로 epoch은 10번만 해줍니다.\n",
        "\n",
        "\n",
        "\n",
        "mnist_train = dset.MNIST(\"./\",train=True, transform = transforms.ToTensor(),target_transform=None, download = True)\n",
        "mnist_test = dset.MNIST(\"./\", train=False, transform = transforms.ToTensor(), target_transform=None, download = True)\n",
        "#torchvision.datasets라이브러리에서 MNIST데이터를 받아오는 코드\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(mnist_train,batch_size=batch_size,shuffle=True,num_workers=2,drop_last=True)\n",
        "test_loader = torch.utils.data.DataLoader(mnist_test,batch_size=batch_size,shuffle=False,num_workers=2,drop_last=True)\n",
        "#받아온 데이터를 학습하기 위해 나누어줍니다.\n",
        "#batch_size선언, shuffle : 데이터를 무작위로 섞을때\n",
        "#num_workers : 데이터를 묶을때 사용하는 프로세스 갯수\n",
        "#drop_last : 묶고 남은 자투리 데이터들은 버릴지 말지\n",
        "\n",
        "class CNN(nn.Module):\n",
        "    #C++에서 사용되는 Class 선언(파이썬 : 객체지향 언어)\n",
        "    def __init__(self) :\n",
        "        super(CNN,self).__init__()  #Super class로 지금 작성하고있는 클래스 자체를 초기화하기 위함\n",
        "\n",
        "\t\t\t\t# Conv2d : Convolution Filtering이라는 Signal Processing적인 방법으로 이미지를 처리 하는것으로,\n",
        "\t\t\t\t# nn.Conv2d(1,16,5)는 1개필터짜리 입력(28x28 해상도의 이미지, default filter 갯수 = 1)을 받아\n",
        "\t\t\t\t# 16개의 필터로 size 5의 Kernel(Filtering)을 하는것입니다.\n",
        "\t\t\t\t# 기본적으로 CNN은 신호/영상처리에 대한 기본적인 이해가 있어야합니다.\n",
        "\t\t\t\t# Kernel size가 5인경우, Convoltuion을 하게 되면 4개의 pixel이 사라지게 되어(28x28)의\n",
        "\t\t\t\t# input 이미지가 (24x24)가 됩니다.이런식으로 이미지의 사이즈를 줄여가며 강한 특징만을 추려나가는게\n",
        "\t\t    # CNN입니다. MaxPooling을 중간중간 섞어줌으로써, Convolution보다 더욱 강하게 Feature들을\n",
        "\t\t\t\t# 뽑아내줍니다.\n",
        "        self.layer = nn.Sequential(\n",
        "            nn.Conv2d(1,16,5), # input 1, output 16 filter 5\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(16,32,5),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2,2),\n",
        "            nn.Conv2d(32,64,5),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2,2)\n",
        "        )\n",
        "        self.fc_layer = nn.Sequential(\n",
        "            nn.Linear(64*3*3,100),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(100,10)\n",
        "        )\n",
        "        #self.layer : CNN이 끝난 이후, 최종적으로 나오는 결과물은 [batch_size,64,3,3]입니다.\n",
        "        #즉, 256개의 이미지 묶음씩 64개의 필터, (3x3)의 이미지가 남게 되는것으로, pixel갯수로 따지면 64*3*3이 나오게 되는것입니다.\n",
        "        #따라서, 64*3*3의 결과값을 nn.Linear(100,10)을 통해 최종적으로 10개의 값이 나오게하는데\n",
        "        #이 10개의 값이 내가 넣은 이미지가 0~9(10개)중 어떤것일지에 대한 각각의 확률입니다.\n",
        "\n",
        "    def forward(self,x):\n",
        "        out = self.layer(x)\n",
        "        out = out.view(batch_size, -1)\n",
        "        out = self.fc_layer(out)\n",
        "        return out\n",
        "        #CNN함수의 전체적인 그림으로, Conv2d -> Linear Regression -> 추정 입니다.\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "  #이부분은 굳이 안해주셔도 됩니다. GPU를 사용할 수 없는경우 CPU를 쓰겠다는 것으로, 이부분을 주석처리하고\n",
        "  # model = CNN()로만 해주셔도 됩니다.\n",
        "model = CNN().to(device)\n",
        "loss_func = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(),lr=learning_rate)\n",
        "#Cross Entropy Loss function, Adam optimizer\n",
        "\n",
        "loss_arr = []\n",
        "for i in range(num_epoch):\n",
        "    for j,[image,label] in enumerate(train_loader):\n",
        "        x = image.to(device)\n",
        "        #mnist 학습용 data를 불러옵니다.(28x28)\n",
        "        y_ = label.to(device)\n",
        "        #각각의 data들이 0~9중 어떤숫자인지도 불러옵니다.\n",
        "        optimizer.zero_grad()\n",
        "        #optimizer 초기화\n",
        "        output = model.forward(x)\n",
        "        #학습용 데이터로 CNN 실시\n",
        "        loss = loss_func(output,y_)\n",
        "        #학습해서 추정해낸 값과, 실제 라벨된 값 비교\n",
        "        loss.backward()\n",
        "        #오차만큼 다시 Back Propagation 시행\n",
        "        optimizer.step()\n",
        "        #Back Propagation시 ADAM optimizer 매 Step마다 시행\n",
        "        if j % 1000 == 0 :\n",
        "            print(loss)\n",
        "            loss_arr.append(loss.cpu().detach().numpy())\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for image,label in test_loader :\n",
        "        x = image.to(device)\n",
        "        y_ = label.to(device)\n",
        "        output = model.forward(x)\n",
        "        _,output_index = torch.max(output,1)\n",
        "        total += label.size(0)\n",
        "        correct += (output_index == y_).sum().float()\n",
        "    print(\"Accuracy of Test Data : {}\".format(100*correct/total))"
      ]
    }
  ]
}