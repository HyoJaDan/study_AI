{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMYoQO/WlspczUiPFbRArZ0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HyoJaDan/VGGNet/blob/main/%08VGGNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uTUOeiZtnQ6L",
        "outputId": "1b44e090-7b02-4b7a-c3a3-b4df547c5a73"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "tensor(2.3027, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9017, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(1.4814, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(1.3852, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(1.2654, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.8127, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.8560, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.7536, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5218, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4254, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2794, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2096, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2843, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1841, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1720, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2329, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3062, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1671, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0607, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1315, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0520, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1285, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1190, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0129, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1136, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0733, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0081, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0392, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0166, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0508, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0341, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0367, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0145, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0098, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0298, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0589, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0215, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0089, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0674, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0151, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0333, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1376, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0035, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0065, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0045, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0090, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0063, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0360, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0008, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0012, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0510, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0034, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0346, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1257, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0470, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0082, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0178, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0229, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0187, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0135, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0318, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0419, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0525, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0044, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0063, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0055, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0451, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0048, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0368, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0170, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0016, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0017, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0539, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0001, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0323, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0469, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0001, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0156, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0677, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0001, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0016, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0129, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0008, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0002, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0342, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0012, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0097, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0133, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0030, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0003, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0298, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0287, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0095, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0017, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0014, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0129, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0004, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0044, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Accuracy of Test Data : 81.6199951171875\n"
          ]
        }
      ],
      "source": [
        "import torchvision\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.init as init\n",
        "import torch\n",
        "import torchvision.models as models\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from tqdm import trange\n",
        "batch_size = 100\n",
        "learning_rate = 0.0002\n",
        "num_epoch = 100\n",
        "\n",
        "# Transform 정의\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "# CIFAR10 TRAIN 데이터 정의\n",
        "cifar10_train = datasets.CIFAR10(root=\"../Data/\", train=True, transform=transform, target_transform=None, download=True)\n",
        "\n",
        "# CIFAR10 TEST 데이터 정의\n",
        "cifar10_test = datasets.CIFAR10(root=\"../Data/\", train=False, transform=transform, target_transform=None, download=True)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(cifar10_train,batch_size=batch_size,shuffle=True,num_workers=2,drop_last=True)\n",
        "test_loader = torch.utils.data.DataLoader(cifar10_test,batch_size=batch_size,shuffle=False,num_workers=2,drop_last=True)\n",
        "#받아온 데이터를 학습하기 위해 나누어줍니다.\n",
        "#batch_size선언, shuffle : 데이터를 무작위로 섞을때\n",
        "#num_workers : 데이터를 묶을때 사용하는 프로세스 갯수\n",
        "#drop_last : 묶고 남은 자투리 데이터들은 버릴지 말지\n",
        "\n",
        "\n",
        "def conv_2_block(in_dim,out_dim):\n",
        "    model = nn.Sequential(\n",
        "        nn.Conv2d(in_dim,out_dim,kernel_size=3,padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(out_dim,out_dim,kernel_size=3,padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(2,2)\n",
        "    )\n",
        "    return model\n",
        "def conv_3_block(in_dim,out_dim):\n",
        "    model = nn.Sequential(\n",
        "        nn.Conv2d(in_dim,out_dim,kernel_size=3,padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(out_dim,out_dim,kernel_size=3,padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(out_dim,out_dim,kernel_size=3,padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(2,2)\n",
        "    )\n",
        "    return model\n",
        "class VGG(nn.Module):\n",
        "    def __init__(self, base_dim, num_classes=10):\n",
        "        super(VGG, self).__init__()\n",
        "        self.feature = nn.Sequential(\n",
        "            conv_2_block(3,base_dim), #64\n",
        "            conv_2_block(base_dim,2*base_dim), #128\n",
        "            conv_3_block(2*base_dim,4*base_dim), #256\n",
        "            conv_3_block(4*base_dim,8*base_dim), #512\n",
        "            conv_3_block(8*base_dim,8*base_dim), #512\n",
        "        )\n",
        "        self.fc_layer = nn.Sequential(\n",
        "            # CIFAR10은 크기가 32x32이므로\n",
        "            nn.Linear(8*base_dim*1*1, 4096),\n",
        "            # IMAGENET이면 224x224이므로\n",
        "            # nn.Linear(8*base_dim*7*7, 4096),\n",
        "            nn.ReLU(True),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(4096, 1000),\n",
        "            nn.ReLU(True),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(1000, num_classes),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.feature(x)\n",
        "\n",
        "        x = x.view(x.size(0), -1)\n",
        "\n",
        "        x = self.fc_layer(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "  #이부분은 굳이 안해주셔도 됩니다. GPU를 사용할 수 없는경우 CPU를 쓰겠다는 것으로, 이부분을 주석처리하고\n",
        "  # model = CNN()로만 해주셔도 됩니다.\n",
        "model = VGG(base_dim=64).to(device)\n",
        "loss_func = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(),lr=learning_rate)\n",
        "#Cross Entropy Loss function, Adam optimizer\n",
        "\n",
        "loss_arr = []\n",
        "for i in range(num_epoch):\n",
        "    for j,[image,label] in enumerate(train_loader):\n",
        "        x = image.to(device)\n",
        "        #mnist 학습용 data를 불러옵니다.(28x28)\n",
        "        y_ = label.to(device)\n",
        "        #각각의 data들이 0~9중 어떤숫자인지도 불러옵니다.\n",
        "        optimizer.zero_grad()\n",
        "        #optimizer 초기화\n",
        "        output = model.forward(x)\n",
        "\n",
        "        #학습용 데이터로 CNN 실시\n",
        "        loss = loss_func(output,y_)\n",
        "        #학습해서 추정해낸 값과, 실제 라벨된 값 비교\n",
        "        loss.backward()\n",
        "        #오차만큼 다시 Back Propagation 시행\n",
        "        optimizer.step()\n",
        "        #Back Propagation시 ADAM optimizer 매 Step마다 시행\n",
        "        if j % 1000 == 0 :\n",
        "            print(loss)\n",
        "            loss_arr.append(loss.cpu().detach().numpy())\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for image,label in test_loader :\n",
        "        x = image.to(device)\n",
        "        y_ = label.to(device)\n",
        "        output = model.forward(x)\n",
        "        _,output_index = torch.max(output,1)\n",
        "        total += label.size(0)\n",
        "        correct += (output_index == y_).sum().float()\n",
        "    print(\"Accuracy of Test Data : {}\".format(100*correct/total))"
      ]
    }
  ]
}
